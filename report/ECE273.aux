\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{imagenet}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Convolutional Neural Networks}{1}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Theoretical basis: Convolutional neural networks}{1}{subsection.2.1}}
\citation{backprop}
\citation{imagenet}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The architecture of our CNN.}}{2}{figure.1}}
\newlabel{fig1}{{1}{2}{The architecture of our CNN}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Overall architecture}{2}{subsection.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Sub-model Convolutional Network}{2}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Dropout and sub-model combination}{3}{subsection.3.1}}
\newlabel{equation1}{{11}{3}{Dropout and sub-model combination}{equation.3.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Sub-model combination in non-dropout CNN}{4}{subsection.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Convex Loss functions}{4}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Cross-entropy}{4}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Hinge Loss}{4}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Multiclass Deep Neural Network with Hinge Loss}{5}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}One-Versus-All}{5}{subsubsection.4.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}One-Versus-One}{5}{subsubsection.4.3.2}}
\citation{theano}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  Deep Neural Network with One-Versus-One Hinge Loss. Ultimate layer consists of $9\times 10/2=45$ units. For each training data, only 9 units (colored blue) are activated.}}{6}{figure.2}}
\newlabel{mcsvm}{{2}{6}{Deep Neural Network with One-Versus-One Hinge Loss. Ultimate layer consists of $9\times 10/2=45$ units. For each training data, only 9 units (colored blue) are activated}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Ranking Loss}{6}{subsection.4.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experiments}{6}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Sub-model convolutional network}{6}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Sub-model combination results}{6}{subsubsection.5.1.1}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Baseline: Accuracies of dropout/non-dropout networks}}{7}{table.1}}
\newlabel{table1}{{1}{7}{Baseline: Accuracies of dropout/non-dropout networks}{table.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Accuracies with different loss functions and the corresponding weight decay}}{7}{table.2}}
\newlabel{table2}{{2}{7}{Accuracies with different loss functions and the corresponding weight decay}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}The role of dropout}{7}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Convolutional network with different convex loss functions}{7}{subsection.5.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Classification results}{7}{subsubsection.5.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  Accuracy v.s. number of sub-models.}}{8}{figure.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Accuracy-number of sub-models for dropout network}}}{8}{figure.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Accuracy v.s. number of sub-models for nondropout network}}}{8}{figure.3}}
\newlabel{accuracies}{{3}{8}{Accuracy v.s. number of sub-models}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  Histograms of sub-models.}}{9}{figure.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Histogram of accuracies of sub-models of dropout network}}}{9}{figure.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Histogram of accuracies of sub-models of nondropout network}}}{9}{figure.4}}
\newlabel{hist}{{4}{9}{Histograms of sub-models}{figure.4}{}}
\bibstyle{splncs}
\bibdata{ECE273}
\bibcite{imagenet}{1}
\bibcite{backprop}{2}
\bibcite{theano}{3}
\bibcite{gregor}{4}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Comparison for different loss functions while training}}{10}{figure.5}}
\newlabel{conv}{{5}{10}{Comparison for different loss functions while training}{figure.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Convergence comparison}{10}{subsubsection.5.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{10}{section.6}}
